---
title: DATA621 HW 5
author: IvanTikhonov, Seung Min Song, Alice Friedman
output:  
  html_document:
    toc: true
    toc_float: true
    show_toggle: true
  pdf_document:
  includes:
  in_header: header.html
css: ./lab.css
highlight: pygments
theme: cerulean
toc: true
toc_float: true
linkcolor: blue
date: "2023-3-12"
---

```{r setup, include=FALSE}
library(dplyr)
library(tidyr)
library(MASS)
library(car)
library(psych)
library(ggplot2)
library(gridExtra) 
library(hrbrthemes)
library(viridis)
library(corrplot)
library(FactoMineR)
library(VIFCP)
library(knitr)
library(kableExtra)
library(Hmisc)
library(pROC)
library(binr)
library(mice)
library(UpSetR)
library(randomForest)
library(class)
library(Metrics)
options(warn=-1)
```

Overview
In this homework assignment, you will explore, analyze and model a data set containing information on
approximately 12,000 commercially available wines. The variables are mostly related to the chemical properties of
the wine being sold. The response variable is the number of sample cases of wine that were purchased by wine
distribution companies after sampling a wine. These cases would be used to provide tasting samples to
restaurants and wine stores around the United States. The more sample cases purchased, the more likely is a
wine to be sold at a high end restaurant. A large wine manufacturer is studying the data in order to predict the
number of wine cases ordered based upon the wine characteristics. If the wine manufacturer can predict the
number of cases, then that manufacturer will be able to adjust their wine offering to maximize sales.

## 1. Data Exploration

```{r}
train_df <- read.csv("C:/Users/SeungminSong/Downloads/621R/wine-training-data.csv")
test_df <- read.csv("C:/Users/SeungminSong/Downloads/621R/wine-evaluation-data.csv")
head(train_df)
```

### Overal Statistics

When examining the distinctive variables in the train_df dataframe, a few noteworthy ones stand out:

* ResidualSugar: This variable denotes the quantity of residual sugar present. Its range is significantly broader than that of other variables when comparing the minimum and maximum values. The value of ResidualSugar can greatly influence the level of sweetness in a beverage.

* AcidIndex: As a crucial factor in describing wine characteristics, AcidIndex represents the acidity index. Unlike other variables, it takes on discrete values and encompasses 14 unique values ranging from 4 to 17. Its categorical nature sets it apart from the rest.

* STARS: This variable assigns a score that indicates the rating of a wine. Ranging from 1 to 4, it possesses relatively fewer distinct values compared to other variables in the dataset.
```{r}
describe(train_df)
```

Data type for all columns of a **train_df**.
```{r}
str(train_df)
```

Change int data type to numeric data type for future analysis.

```{r}
train_df$STARS <- as.numeric(train_df$STARS)
train_df$AcidIndex <- as.numeric(train_df$AcidIndex)
train_df$LabelAppeal <- as.numeric(train_df$LabelAppeal)
```

### Correlation

```{r}
# Remove rows with NA from train_df
train_df_no_na <- train_df[complete.cases(train_df), ]

# Calculate the correlation matrix
M <- cor(train_df_no_na)

# Plot the correlation matrix using corrplot
corrplot(M, method = "number")
```

The relationship between STARS and Target appears to be positive, suggesting that higher STARS ratings may be associated with higher Target sales.
```{r}
corr_matrix <- cor(train_df[c("STARS", "TARGET", "LabelAppeal")], use = "complete.obs")
print(corr_matrix)

# print result
print(corr_matrix["TARGET", "STARS"])
print(corr_matrix["TARGET", "LabelAppeal"])
```

When considering the distribution of **Volatile Acidity**, **Alcohol**, **Acid Index**, and **pH** across different STARS categories, it becomes evident that these variables show a relatively even distribution within each STARS group. Consequently, it appears impractical to assess the STARS rating solely based on these variables.
```{r}
p1 <- train_df %>% na.omit() %>% ggplot(aes(factor(STARS), AcidIndex)) + geom_boxplot()
p2 <- train_df %>% na.omit() %>% ggplot(aes(factor(STARS), Alcohol)) + geom_boxplot()
p3 <- train_df %>% na.omit() %>% ggplot(aes(factor(STARS), VolatileAcidity)) + geom_boxplot()
p4 <- train_df %>% na.omit() %>% ggplot(aes(pH, FixedAcidity)) + geom_point(alpha=.1) + geom_smooth()
grid.arrange(p1, p2, p3, p4, ncol=2) 
```

### Multicollinearity

In regression analysis, we typically use a p-value threshold of 0.05 to determine statistical significance. Therefore, independent variables with a p-value less than 0.05 can be considered statistically significant and are likely to have a significant impact on predicting wine quality. In this model, the variables **VolatileAcidity**, **Alcohol**, **LabelAppeal**, and **AcidIndex** all meet this criterion and can be considered relevant in predicting wine quality.

Based on these VIF values, it appears that there is no significant multicollinearity present in your model. All the VIF values are close to 1, suggesting that there is no strong linear relationship between the predictor variables.

```{r}
lm_model <- lm(STARS ~ FixedAcidity + VolatileAcidity + CitricAcid + ResidualSugar + Chlorides + ResidualSugar + Chlorides + FreeSulfurDioxide + TotalSulfurDioxide + Density + pH + Sulphates + Alcohol + LabelAppeal + AcidIndex, data = train_df)

summary(lm_model)

# Check for multicollinearity
vif_values <- vif(lm_model)
print(vif_values)
```

### Missing Values

Search for any missing values. Since the column STARS is an important values, it will be filled in in the data preparation step.

```{r}
colSums(is.na(train_df))
```

### Bar Plot

* Most wines have a quality score of 1 and 2.
* If the score is 3 or 4, it can be judged as a good wine.
```{r}
theme_set(theme_minimal())
ggplot(train_df,aes(STARS)) + geom_histogram(stat="count") +
   xlab("STARS of wines") + ylab("Number of wines") + geom_bar(fill="pink")
```

Bar Plot of **STARS** and **TARGET**. As you can see, the higher the STARS, the higher the average TARGET.

```{r}
TARGET_STARS_df <- train_df %>% 
  filter(!is.na(STARS)) %>%
        group_by(STARS) %>% 
        summarise(TARGET = mean(TARGET))
TARGET_STARS_df

```

```{r}

ggplot(train_df, aes(x = STARS, y = TARGET, color = STARS, fill = STARS)) +
  geom_bar(data = TARGET_STARS_df, stat = "identity", alpha = .3) + 
    #ggrepel::geom_text_repel(aes(label = STARS), color = "black", size = 2.5, segment.color = "grey") +
      #geom_point() +
        guides(color = "none", fill = "none") +
        theme_bw() +
        labs(
          title = "STARS & TARGET",
          x = "STARS",
          y = "TARGET"
        )
```

### Basic Plots

Everything looks pretty close to a normal distribution. Also, LabelAppeal, AcidIndex, and STARS are actually categorical variables.

```{r}
datasub <- reshape2::melt(train_df)
ggplot2::ggplot(datasub) +
  ggplot2::aes(x = value) + 
  ggplot2::geom_density(fill = "skyblue") + 
  ggplot2::facet_wrap(~variable, scales = 'free')

```

## 2. DATA PREPARATION

### Missing Value

Since STARS and TARGET have a moderate positive correlation, build the linear regression model to predict missing value for STARS. It should be noted that there are many missing values in the STARS column, which may limit the accuracy of any conclusions drawn from the analysis.

**TARGET** and **LabelAppeal** variables have a strong influence on the response variable.

```{r}
missing_STARS <- subset(train_df, is.na(STARS))

lm_model_STARS <- lm(STARS ~ TARGET + LabelAppeal, data = train_df)

predicted_STARS <- predict(lm_model_STARS, newdata = missing_STARS)

predicted_STARS_rounded <- round(predicted_STARS)

train_df$STARS[is.na(train_df$STARS)] <- predicted_STARS_rounded

summary(lm_model_STARS)

head(train_df)
```

Delete all rows with NA values for more accurate future analysis.
```{r}
train_df <- train_df[complete.cases(train_df),]
```
### Data Types

* It has 16 variables and 12795 data.
* All variables are continuous variables.

Change the datatypes of a few variables. Convert specific columns to factors in separate data frames without altering the original data frames,

```{r}
str(train_df)
```

```{r}
train_df_factors <- train_df
train_df_factors$LabelAppeal <- as.factor(train_df_factors$LabelAppeal)
train_df_factors$AcidIndex <- as.factor(train_df_factors$AcidIndex)
train_df_factors$STARS <- as.factor(train_df_factors$STARS)

test_df_factors <- test_df
test_df_factors$LabelAppeal <- as.factor(test_df_factors$LabelAppeal)
test_df_factors$AcidIndex <- as.factor(test_df_factors$AcidIndex)
test_df_factors$STARS <- as.factor(test_df_factors$STARS)
```

### Box Cox

Column AcidIndex is not normally distributed. Therefore secure normality through the Box-Cox Transformation.

```{r}
ggplot(train_df, aes(x = AcidIndex)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Histogram of AcidIndex", x = "AcidIndex", y = "Frequency")

```

```{r}
# Perform Box-Cox transformation
bc_result <- boxCox(train_df$AcidIndex ~ 1, data = train_df)

# Extract lambda value
lambda <- bc_result$x[which.max(bc_result$y)]

# Apply Box-Cox transformation using the lambda value
transformed_AcidIndex <- if (lambda != 0) {
  (train_df$AcidIndex^lambda - 1) / lambda
} else {
  log(train_df$AcidIndex)
}

# Generate Q-Q plot
qqnorm(transformed_AcidIndex)
qqline(transformed_AcidIndex)

# Create a histogram of the transformed AcidIndex
ggplot(data.frame(AcidIndex = transformed_AcidIndex), aes(x = AcidIndex)) +
  geom_histogram(fill = "skyblue", color = "black") +
  labs(title = "Histogram of Transformed AcidIndex", x = "Transformed AcidIndex", y = "Frequency")

```

## 3. Model

In order to analyze the data and make predictions, we proceeded by building both a Poisson model, binomial regression model, multiple leaner regression utilizing these models to explore the relationships and patterns within the dataset. Furthermore, to ensure accurate assessment and validation of our models, we split the training data into distinct subsets, allowing us to effectively evaluate their performance and generalization capabilities.


```{r}
set.seed(123)
partition <- sample(1:nrow(train_df), size=nrow(train_df)*0.7,replace=FALSE)

train.data <-train_df[partition, ]
test.data <- train_df[-partition, ]

target <- test.data$`TARGET`
```

### Model 1
```{r}
model1 <- glm(TARGET ~., data=train.data, family = poisson)
summary(model1)
```

### Model 2
```{r}
model2<- glm(TARGET ~ VolatileAcidity + Chlorides + FreeSulfurDioxide + TotalSulfurDioxide + Density + Alcohol + LabelAppeal + AcidIndex + STARS ,data=train.data, family = poisson)
summary(model2)
```

### Model 3
```{r}
model3 <- glm(TARGET ~., data=train.data)
summary(model3)
```

### Model 4
```{r}
model4 <- glm(TARGET~ VolatileAcidity + Chlorides + FreeSulfurDioxide + TotalSulfurDioxide + Density + Alcohol + LabelAppeal + AcidIndex + STARS , data=train.data)
summary(model4)
```

### Model 5

**Random Forest Model**. Correlation with STARS and Label Appear is the highest.
```{r}
set.seed(1810)

data_rf <- randomForest(TARGET ~ ., data = train_df)

data_rf

opar <- par(mfrow=c(1,2))

plot(data_rf)

varImpPlot(data_rf)

par(opar)

dev.off() 
```

## 4. Model Selection

The models can be compared effectively by examining their respective accuracy scores, which serve as a reliable metric for evaluating their performance in accurately predicting the desired outcome. By analyzing and contrasting the accuracy scores of the models, valuable insights can be gained to facilitate informed decision-making regarding the most appropriate model for the given analysis or task at hand. This comparative assessment of accuracy scores enables a comprehensive evaluation of the models' predictive capabilities, aiding in the selection of the optimal model for the desired objective.

### Model 1

```{r}
predictions <- as.data.frame(predict(model1, newdata = test.data))

accuracy_df <- target

accuracy_df <- merge(accuracy_df, predictions)
accuracy_df$error <- abs(accuracy_df$x - accuracy_df$`predict(model1, newdata = test.data)`)
accuracy_df$error_percentage <- ((accuracy_df$`predict(model1, newdata = test.data)` - accuracy_df$x)/accuracy_df$x) * 100
avg_error <- mean(accuracy_df$error)
avg_percentage_error <- mean(accuracy_df$error_percentage)
print(avg_error)
```

```{r}
print(avg_percentage_error)
```


### Model 2
```{r}
predictions <- as.data.frame(predict(model2, newdata = test.data))

accuracy_df <- target

accuracy_df <- merge(accuracy_df, predictions)
accuracy_df$error <- abs(accuracy_df$x - accuracy_df$`predict(model2, newdata = test.data)`)
accuracy_df$error_percentage <- ((accuracy_df$`predict(model2, newdata = test.data)` - accuracy_df$x)/accuracy_df$x) * 100
avg_error <- mean(accuracy_df$error)
avg_percentage_error <- mean(accuracy_df$error_percentage)
print(avg_error)
```

```{r}
print(avg_percentage_error)
```


### Model 3
```{r}
predictions <- as.data.frame(predict(model3, newdata = test.data))

accuracy_df <- target

accuracy_df <- merge(accuracy_df, predictions)
accuracy_df$error <- abs(accuracy_df$x - accuracy_df$`predict(model3, newdata = test.data)`)
accuracy_df$error_percentage <- ((accuracy_df$`predict(model3, newdata = test.data)` - accuracy_df$x)/accuracy_df$x) * 100
avg_error <- mean(accuracy_df$error)
avg_percentage_error <- mean(accuracy_df$error_percentage)
print(avg_error)
```
```{r}
print(avg_percentage_error)
```

### Model 4
```{r}
predictions <- as.data.frame(predict(model4, newdata = test.data))

accuracy_df <- target

accuracy_df <- merge(accuracy_df, predictions)
accuracy_df$error <- abs(accuracy_df$x - accuracy_df$`predict(model4, newdata = test.data)`)
accuracy_df$error_percentage <- ((accuracy_df$`predict(model4, newdata = test.data)` - accuracy_df$x)/accuracy_df$x) * 100
avg_error <- mean(accuracy_df$error)
avg_percentage_error <- mean(accuracy_df$error_percentage)
print(avg_error)
```

```{r}
print(avg_percentage_error)
```
The NaNs are due to the fact that some of the wines simply didn’t sell a case. So that would make a 0 in the denominator. Thus, it won’t work. We can still check the average rate however.


### Model 5

```{r}
y_obs <- test.data$TARGET
yhat_rf <- predict(data_rf, newdata = test.data)

rmse_value <- rmse(y_obs, yhat_rf)
rmse_value
```
### Predictions

```{r}

#predictions <- as.data.frame(predict(model1, newdata = test_df))
#test_df$predictions <- predictions
#results <- test_df[c("IN", "predictions")]
```











